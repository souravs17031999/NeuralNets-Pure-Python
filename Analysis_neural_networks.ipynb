{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analysis_neural_networks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0b5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eQwFA1bQqIkb"
      },
      "source": [
        "# Project :Deeper understanding of how neural networks learn(Part - I)\n",
        "## Objective : To go through how the matrix changes its shape and make its way through the layers to the final output layer and how updation of weights effects the overall loss and prediction power of the network !\n",
        "\n",
        "### The codes have been highly influenced by the one given on the Andrew Trask's blog page\n",
        "\n",
        "\n",
        "The following is like a walk-through tutorial, so i hope you enjoy !\n",
        "\n",
        "```\n",
        "references\n",
        "```\n",
        "[Andrew Trask's code for neural network](https://iamtrask.github.io/2015/07/12/basic-python-network/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UT_A3JWOqT_P"
      },
      "source": [
        "### packages import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "joBriGROVcr-",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dERwGmGsqZrz"
      },
      "source": [
        "### Function for training the network made of 3 input nodes and 1 output node"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SF8lNlB1jd7-",
        "colab": {}
      },
      "source": [
        "# function for feedforward and backpropogation step \n",
        "def feed_forward_backpropogation_train(n, X, y, weights_input_to_hidden, weights_hidden_to_output, shapes = True):\n",
        "    '''\n",
        "    n : number of iterations\n",
        "    X : Input data matrix \n",
        "    y : actual target (label)\n",
        "    weights_input_to_hidden : weights matrix from input to hidden layer\n",
        "    weights_hidden_to_output : weights matrix from hidden to output layer\n",
        "    shapes : if shapes required to be printed or not \n",
        "    '''\n",
        "  if shapes == True:\n",
        "    for j in range(n):\n",
        "      print(\"inside the loop....\")\n",
        "      h1 = 1/(1+np.exp(-(np.dot(X,weights_input_to_hidden))))\n",
        "      print(f\"first output shape : {X.shape} x {weights_input_to_hidden.shape} =  {h1.shape}\")\n",
        "      print(f\"shape of h1 : {h1.shape}\")\n",
        "      print(f\"shape of weights_hidden_to_output : {weights_hidden_to_output.shape}\")\n",
        "      output = 1/(1+np.exp(-(np.dot(h1,weights_hidden_to_output))))\n",
        "      print(f\"second outupt shape {h1.shape} x {weights_hidden_to_output.shape} = {output.shape}\")\n",
        "      print(f\"predicted :\")\n",
        "      print(output)\n",
        "      print()\n",
        "      output_delta = (y - output)*(output*(1-output))\n",
        "      h1_delta = output_delta.dot(weights_hidden_to_output.T) * (h1 * (1-h1))\n",
        "      weights_hidden_to_output += h1.T.dot(output_delta)\n",
        "      weights_input_to_hidden += X.T.dot(h1_delta)\n",
        "  else:\n",
        "    for j in range(n):\n",
        "      # feedforward pass\n",
        "      h1 = 1/(1+np.exp(-(np.dot(X,weights_input_to_hidden))))\n",
        "      output = 1/(1+np.exp(-(np.dot(h1,weights_hidden_to_output))))\n",
        "      # backpropogation of error \n",
        "      output_delta = (y - output)*(output*(1-output))\n",
        "      h1_delta = output_delta.dot(weights_hidden_to_output.T) * (h1 * (1-h1))\n",
        "      # updation of weights\n",
        "      weights_hidden_to_output += h1.T.dot(output_delta)\n",
        "      weights_input_to_hidden += X.T.dot(h1_delta)\n",
        "  return weights_input_to_hidden, weights_hidden_to_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VD1Lx8CmqwuS"
      },
      "source": [
        "### Let's understand the code one by one by actually seeing the shapes of matrix as they go from layer to layer and how they are changed in the way...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbU0TZYLRY1M",
        "colab_type": "text"
      },
      "source": [
        "Here we are using a neural network consisting of one hidden layer(containing one node) and one output layer (including input layer which we don't necessarily count as a layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W18dO_zrcl8N",
        "outputId": "7a698640-b78e-4734-8e72-fcaf95c10975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        }
      },
      "source": [
        "# Here we start our analysis by taking input examples and outputs.\n",
        "X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
        "print(\"X (training examples)\")\n",
        "print(X)\n",
        "print(f\"shape X: {X.shape}\")\n",
        "y = np.array([[0,1,1,0]]).T\n",
        "print(\"Y (actual target)\")\n",
        "print(y)\n",
        "print(f\"shape of Y : {y.shape}\")\n",
        "weights_input_to_hidden = 2*np.random.random((3,4)) - 1\n",
        "print(\"weights initialized from input to hidden:\")\n",
        "print(weights_input_to_hidden)\n",
        "print(f\"shape of weights_input_to_hidden: {weights_input_to_hidden.shape}\")\n",
        "weights_hidden_to_output = 2*np.random.random((4,1)) - 1\n",
        "print(\"weights iniatialized from hidden to output:\")\n",
        "print(weights_hidden_to_output)\n",
        "print(f\"shape of weights_hidden_to_output: {weights_hidden_to_output.shape}\")\n",
        "\n",
        "print(\"Let's play with one time pass and check the shapes of matrix data as they pass from input to output:\")\n",
        "weights_input_to_hidden, weights_hidden_to_output = feed_forward_backpropogation_train(1, X, y, weights_input_to_hidden, weights_hidden_to_output, True)\n",
        "\n",
        "\n",
        "print(\"new weights from input to hidden\")\n",
        "print(weights_input_to_hidden)\n",
        "print(\"new wegiths from hidden to output\")\n",
        "print(weights_hidden_to_output)\n",
        "\n",
        "print()\n",
        "print(\"Let's now iterate more and check how these weights get updated\")\n",
        "weights_input_to_hidden, weights_hidden_to_output = feed_forward_backpropogation_train(10000, X, y, weights_input_to_hidden, weights_hidden_to_output)\n",
        "\n",
        "\n",
        "print(\"new weights from input to hidden\")\n",
        "print(weights_input_to_hidden)\n",
        "print(\"new weights from hidden to output\")\n",
        "print(weights_hidden_to_output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (training examples)\n",
            "[[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [1 1 1]]\n",
            "shape X: (4, 3)\n",
            "Y (actual target)\n",
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n",
            "shape of Y : (4, 1)\n",
            "weights initialized from input to hidden:\n",
            "[[-0.95248212  0.94801853 -0.06155864 -0.39234065]\n",
            " [ 0.09271474  0.07193927  0.71815955  0.63630801]\n",
            " [-0.27803125 -0.27031507  0.32315005 -0.38833101]]\n",
            "shape of weights_input_to_hidden: (3, 4)\n",
            "weights iniatialized from hidden to output:\n",
            "[[ 0.19642532]\n",
            " [ 0.45506969]\n",
            " [ 0.56397485]\n",
            " [-0.62344138]]\n",
            "shape of weights_hidden_to_output: (4, 1)\n",
            "Let's play with one time pass and check the shapes of matrix data as they pass from input to output:\n",
            "inside the loop....\n",
            "first output shape : (4, 3) x (3, 4) =  (4, 4)\n",
            "shape of h1 : (4, 4)\n",
            "shape of weights_hidden_to_output : (4, 1)\n",
            "second outupt shape (4, 4) x (4, 1) = (4, 1)\n",
            "predicted :\n",
            "[[0.58827215]\n",
            " [0.58924374]\n",
            " [0.61515074]\n",
            " [0.61715719]]\n",
            "\n",
            "new weights from input to hidden\n",
            "[[-0.95461549  0.94281835 -0.06524971 -0.3819703 ]\n",
            " [ 0.09229036  0.06867838  0.7126517   0.64365783]\n",
            " [-0.28218765 -0.28023282  0.31069686 -0.37182911]]\n",
            "new wegiths from hidden to output\n",
            "[[ 0.16534501]\n",
            " [ 0.39959341]\n",
            " [ 0.50026153]\n",
            " [-0.66421253]]\n",
            "\n",
            "Let's now iterate more and check how these weights get updated\n",
            "new weights from input to hidden\n",
            "[[-6.7052325   1.18180632  3.23274259 -5.12925888]\n",
            " [ 5.20302659  0.54319827  3.02951548  6.72972856]\n",
            " [-2.39163355  0.41617517  0.13267     2.17696983]]\n",
            "new weights from hidden to output\n",
            "[[10.09316813]\n",
            " [ 0.84866199]\n",
            " [ 4.31944962]\n",
            " [-9.7516889 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I4JZd6cDq_tu"
      },
      "source": [
        "### Function to make a single pass through the network with updated weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lrB-UObkoGZY",
        "colab": {}
      },
      "source": [
        "# function to do a single pass run through the network to predict the output \n",
        "def run_network(X, weights_input_to_hidden, weights_hidden_to_output):\n",
        "    '''\n",
        "    X : input data matrix\n",
        "    weights_input_to_hidden : weights matrix from input to hidden layer\n",
        "    weights_hidden_to_output : weights matrix from hidden to output layer\n",
        "    '''\n",
        "      h1 = 1/(1+np.exp(-(np.dot(X,weights_input_to_hidden))))\n",
        "      output = 1/(1+np.exp(-(np.dot(h1,weights_hidden_to_output))))\n",
        "      return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cNrc21kJrGwE"
      },
      "source": [
        "### Defining error (here we take [mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "13wfmGminkJn",
        "colab": {}
      },
      "source": [
        "# function to calculate the error \n",
        "def MSE(y, Y):\n",
        "    '''\n",
        "    y : actual label (matrix)\n",
        "    Y : predicted label (matrix)\n",
        "    '''\n",
        "  return np.mean((y - Y)**2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iCMwCd0drNTA"
      },
      "source": [
        "### Here we actually see how increasing the training of network decreases overall loss but mind it this is training loss !\n",
        "### Actual testing loss is the one which is over unseen data !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CaomDCq3ljNV",
        "outputId": "ff411746-00c9-4da9-9fcd-7d4b457c3f7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weights_input_to_hidden, weights_hidden_to_output = feed_forward_backpropogation_train(10000, X, y, weights_input_to_hidden, weights_hidden_to_output)\n",
        "error = MSE(y, run_network(X, weights_input_to_hidden, weights_hidden_to_output))\n",
        "print(error)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.84720358988406e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dJMP2xWxpocz",
        "outputId": "9840b743-24e6-4b91-e79a-297d6db25f0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weights_input_to_hidden, weights_hidden_to_output = feed_forward_backpropogation_train(20000, X, y, weights_input_to_hidden, weights_hidden_to_output)\n",
        "error = MSE(y, run_network(X1, weights_input_to_hidden, weights_hidden_to_output))\n",
        "print(error)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.268337988998213e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cRsvd5ySpvad",
        "outputId": "7fa71953-709f-4d15-93be-75d4c93adb07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weights_input_to_hidden, weights_hidden_to_output = feed_forward_backpropogation_train(40000, X, y, weights_input_to_hidden, weights_hidden_to_output)\n",
        "error = MSE(y, run_network(X, weights_input_to_hidden, weights_hidden_to_output))\n",
        "print(error)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.241752187774674e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6JlRzLpkqB0Q",
        "outputId": "169a25e2-6752-4711-d75d-cde5a70ee150",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weights_input_to_hidden, weights_hidden_to_output = feed_forward_backpropogation_train(100000, X, y, weights_input_to_hidden, weights_hidden_to_output)\n",
        "error = MSE(y, run_network(X, weights_input_to_hidden, weights_hidden_to_output))\n",
        "print(error)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.803759988643886e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNi48KaZRY1n",
        "colab_type": "text"
      },
      "source": [
        "#### Feel free to explore more as everything is Open Sourced !\n"
      ]
    }
  ]
}
